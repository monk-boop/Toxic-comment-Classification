{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hiSSQrRnhLeW"
   },
   "source": [
    "# Toxic Comment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The threat of abuse and harassment online means that many people stop expressing themselves and give up on seeking different opinions. Platforms struggle to effectively facilitate conversations, leading many communities to limit or completely shut down user comments.\n",
    "\n",
    "\n",
    "\n",
    "In this competition, we’re challenged to build a multi-headed model that’s capable of detecting different types of of toxicity like threats, obscenity, insults, and identity-based hate better than Perspective’s current models. We’ll be using a dataset of comments from Wikipedia’s talk page edits. Improvements to the current model will hopefully help online discussion become more productive and respectful.\n",
    "\n",
    "Disclaimer: the dataset for this competition contains text that may be considered profane, vulgar, or offensive.\n",
    "\n",
    "Contest link: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Crawl - Fasttext Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "l7g1zuvW6d40",
    "outputId": "45bc2098-5214-42e6-b553-a7610d99298f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-06 11:04:09--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.20.22.166, 104.20.6.166, 2606:4700:10::6814:6a6, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.20.22.166|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1523785255 (1.4G) [application/zip]\n",
      "Saving to: ‘crawl-300d-2M.vec.zip’\n",
      "\n",
      "crawl-300d-2M.vec.z 100%[===================>]   1.42G  47.8MB/s    in 30s     \n",
      "\n",
      "2020-02-06 11:04:45 (47.8 MB/s) - ‘crawl-300d-2M.vec.zip’ saved [1523785255/1523785255]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: dl.fbaipublicfiles.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.117 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Referer: https://fasttext.cc/docs/en/english-vectors.html\" --header=\"Cookie: __cfduid=d9bce14e3ad5d42528e65276ed8866b581579087931\" --header=\"Connection: keep-alive\" \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\" -O \"crawl-300d-2M.vec.zip\" -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QTlcgjvfhPC4"
   },
   "source": [
    "### Twitter Word Vectrors download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "fxru8Knw-Wb6",
    "outputId": "d1a350d5-c64f-4a5e-a042-7b1e0c6d3afa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-23 11:32:30--  http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1520408563 (1.4G) [application/zip]\n",
      "Saving to: ‘glove.twitter.27B.zip’\n",
      "\n",
      "glove.twitter.27B.z 100%[===================>]   1.42G  2.08MB/s    in 11m 41s \n",
      "\n",
      "2020-02-23 11:44:11 (2.07 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --header=\"Host: downloads.cs.stanford.edu\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.117 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-US,en;q=0.9\" --header=\"Cookie: _ga=GA1.2.2034969121.1579138171; _gid=GA1.2.1181918881.1579138171; _gat=1\" --header=\"Connection: keep-alive\" \"http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\" -O \"glove.twitter.27B.zip\" -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z6t01gMdhRtu"
   },
   "source": [
    "### Importing and extracting zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xukl2xjy6vm_"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('/content/crawl-300d-2M.vec.zip', 'r')\n",
    "zip_ref.extractall('/content/')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42u-gyw2-nJy"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "zip_ref = zipfile.ZipFile('/content/glove.twitter.27B.zip', 'r')\n",
    "zip_ref.extractall('/content/')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "9Z0TujPT3c91",
    "outputId": "de66a81f-5ee4-4182-dff0-965366239b47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iT2AJrUwhfIP"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hC7EA3w861n1",
    "outputId": "f4340bf1-3b67-4bce-8ff2-837a0cca8c57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%tensorflow_version 1.x\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud ,STOPWORDS\n",
    "from PIL import Image\n",
    "import matplotlib_venn as venn\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding,Dropout,Activation,GRU,Conv1D,CuDNNGRU,CuDNNLSTM\n",
    "from keras.layers import SpatialDropout1D,MaxPool1D,GlobalAveragePooling1D,RepeatVector ,Add,PReLU\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D,BatchNormalization,concatenate,TimeDistributed,Flatten\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.optimizers import Adam,SGD,Nadam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.core import Layer  \n",
    "from keras import initializers, regularizers, constraints  \n",
    "from keras import backend as K\n",
    "from nltk.stem import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q0ED7z7RWBP-"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmuRFUU7hjz6"
   },
   "source": [
    "### Import Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pk1F_p0m3eM8"
   },
   "outputs": [],
   "source": [
    "train_a = pd.read_csv('/content/drive/My Drive/self2/train.csv')\n",
    "test_a = pd.read_csv('/content/drive/My Drive/self2/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_18Uidj-4Qm"
   },
   "source": [
    "Objective:\n",
    "To create an EDA/ feature-engineering starter notebook for toxic comment classification.\n",
    "\n",
    "Data Overview:\n",
    "The dataset here is from wiki corpus dataset which was rated by human raters for toxicity. The corpus contains 63M comments from discussions relating to user pages and articles dating from 2004-2015.\n",
    "\n",
    "Different platforms/sites can have different standards for their toxic screening process. Hence the comments are tagged in the following five categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ASJofB0Jjpym"
   },
   "source": [
    "### Check the number of comments that are clean below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NzH02TxZ-_F9"
   },
   "outputs": [],
   "source": [
    "#We will use this to stratify our dataset later on\n",
    "#del train['clean']\n",
    "x= train.iloc[:,2:].sum(axis = 1)\n",
    "train['clean'] = (x==0)\n",
    "train['clean'] = train['clean'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "RjLj_RS0FnU-",
    "outputId": "45fbf2f5-9edf-4052-d607-37c366f7f013"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgoAAAEaCAYAAABw/39TAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=train.iloc[:,2:].sum()\n",
    "#plot\n",
    "plt.figure(figsize=(8,4))\n",
    "ax= sns.barplot(x.index, x.values, alpha=0.8)\n",
    "plt.title(\"# per class\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('Type ', fontsize=12)\n",
    "#adding the text labels\n",
    "rects = ax.patches\n",
    "labels = x.values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_PM-VHZEK66j",
    "outputId": "622ab2d5-1868-4da3-9655-56e64685b254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of clean comments is, 143346 as percentage is  89.83211235124176 %\n"
     ]
    }
   ],
   "source": [
    "print(\"total number of clean comments is,\",train['clean'].sum(axis = 0),\"as percentage is \",float((train['clean'].sum(axis = 0))/train.shape[0]*100), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "iHT2I0b78B_I",
    "outputId": "29927f96-dcff-424b-ee25-68aa81d7910b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               False\n",
       "comment_text     False\n",
       "toxic            False\n",
       "severe_toxic     False\n",
       "obscene          False\n",
       "threat           False\n",
       "insult           False\n",
       "identity_hate    False\n",
       "clean            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ALQe1RQP-Aly",
    "outputId": "f318fa12-fd0a-4d60-9efa-67de2791c18a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              False\n",
       "comment_text    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wOzMc07C976K"
   },
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wF0-97iRUHnL"
   },
   "outputs": [],
   "source": [
    "def text_preprocess(text): \n",
    "    \n",
    "    # Emoticons\n",
    "    text = text.replace(\":/\", \" bad \")\n",
    "    text = text.replace(\":&gt;\", \" sad \")\n",
    "    text = text.replace(\":')\", \" sad \")\n",
    "    text = text.replace(\":-(\", \" frown \")\n",
    "    text = text.replace(\":(\", \" frown \")\n",
    "    text = text.replace(\":s\", \" frown \")\n",
    "    text = text.replace(\":-s\", \" frown \")\n",
    "    text = text.replace(\"&lt;3\", \" heart \")\n",
    "    text = text.replace(\":d\", \" smile \")\n",
    "    text = text.replace(\":p\", \" smile \")\n",
    "    text = text.replace(\":dd\", \" smile \")\n",
    "    text = text.replace(\"8)\", \" smile \")\n",
    "    text = text.replace(\":-)\", \" smile \")\n",
    "    text = text.replace(\":)\", \" smile \")\n",
    "    text = text.replace(\";)\", \" smile \")\n",
    "    text = text.replace(\"(-:\", \" smile \")\n",
    "    text = text.replace(\"(:\", \" smile \")\n",
    "    text = text.replace(\":/\", \" worry \")\n",
    "    text = text.replace(\":&gt;\", \" angry \")\n",
    "    text = text.replace(\":')\", \" sad \")\n",
    "    text = text.replace(\":-(\", \" sad \")\n",
    "    text = text.replace(\":(\", \" sad \")\n",
    "    text = text.replace(\":s\", \" sad \")\n",
    "    text = text.replace(\":-s\", \" sad \")\n",
    "    text = text.replace(\"fu ck\", \"fuck\")\n",
    "    # Shortforms   \n",
    "    text = re.sub(r'[\\w]*don\\'t[\\w]*','do not',text)\n",
    "    text = re.sub(r'[\\w]*i\\'ll[\\w]*','i will',text)\n",
    "    text = re.sub(r'[\\w]*wasn\\'t[\\w]*','was not',text)\n",
    "    text = re.sub(r'[\\w]*there\\'s[\\w]*','there is',text)\n",
    "    text = re.sub(r'[\\w]*i\\'m[\\w]*','i am',text)\n",
    "    text = re.sub(r'[\\w]*won\\'t[\\w]*','will not',text)\n",
    "    text = re.sub(r'[\\w]*let\\'s[\\w]*','let us',text)\n",
    "    text = re.sub(r'[\\w]*i\\'d[\\w]*','i would',text)\n",
    "    text = re.sub(r'[\\w]*they\\'re[\\w]*','they are',text)\n",
    "    text = re.sub(r'[\\w]*haven\\'t[\\w]*','have not',text)\n",
    "    text = re.sub(r'[\\w]*that\\'s[\\w]*','that is',text)\n",
    "    text = re.sub(r'[\\w]*couldn\\'t[\\w]*','could not',text)\n",
    "    text = re.sub(r'[\\w]*aren\\'t[\\w]*','are not',text)\n",
    "    text = re.sub(r'[\\w]*wouldn\\'t[\\w]*','would not',text)\n",
    "    text = re.sub(r'[\\w]*you\\'ve[\\w]*','you have',text)\n",
    "    text = re.sub(r'[\\w]*you\\'ll[\\w]*','you will',text)\n",
    "    text = re.sub(r'[\\w]*what\\'s[\\w]*','what is',text)\n",
    "    text = re.sub(r'[\\w]*we\\'re[\\w]*','we are',text)\n",
    "    text = re.sub(r'[\\w]*doesn\\'t[\\w]*','does not',text)\n",
    "    text = re.sub(r'[\\w]*can\\'t[\\w]*','can not',text)\n",
    "    text = re.sub(r'[\\w]*shouldn\\'t[\\w]*','should not',text)\n",
    "    text = re.sub(r'[\\w]*didn\\'t[\\w]*','did not',text)\n",
    "    text = re.sub(r'[\\w]*here\\'s[\\w]*','here is',text)\n",
    "    text = re.sub(r'[\\w]*you\\'d[\\w]*','you would',text)\n",
    "    text = re.sub(r'[\\w]*he\\'s[\\w]*','he is',text)\n",
    "    text = re.sub(r'[\\w]*she\\'s[\\w]*','she is',text)\n",
    "    text = re.sub(r'[\\w]*weren\\'t[\\w]*','were not',text)\n",
    "    \n",
    "    \n",
    "    # Remove punct except ! and ?\n",
    "    text = re.sub(r\"[,.:|(;@)-/^—#&%$<=>`~{}\\[\\]\\'\\\"]+\\ *\", \" \", text)\n",
    "    # Separate out ! and ?\n",
    "    text = re.sub(\"!\", \" ! \", text)\n",
    "    text = re.sub(\"\\?\", \" ? \", text)\n",
    "  \n",
    "    # Drop numbers\n",
    "    text = re.sub(\"\\\\d+\", \" \", text)\n",
    "        \n",
    "    # Check if at least 3 consecutive substrings are in caps. Add <caps> tag at the end\n",
    "    counter = 0\n",
    "    for substr in text.split():\n",
    "        if (substr.isupper() == True):\n",
    "            counter += 1\n",
    "            if counter >=3:\n",
    "                text = text + \" \" + \"XYZ\" # XYZ chosen for capitals since it is a rare word present in embedding\n",
    "                counter = 0\n",
    "        else:\n",
    "            if counter >=3:\n",
    "                text = text + \" \" + \"XYZ\"\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter = 0\n",
    "    \n",
    "    # Convert to lower\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Lots of words are not present in the fasttext embeddings. Replace them\n",
    "    text = re.sub(r'[\\w]*(fuc|fck|fvc|fuk|fucd)[\\w]*','fuck',text)\n",
    "    text = re.sub(r'[\\w]*fag[\\w]*','gay',text)\n",
    "    text = re.sub(r'[\\w]*gay[\\w]*','gay',text)\n",
    "    text = re.sub(r'[\\w]*peni[\\w]*','dick',text)\n",
    "    text = re.sub(r'[\\w]*(dic|dik)[\\w]*','dick',text)\n",
    "    text = re.sub(r'[\\w]*bi[\\w]*ch[\\w]*','bitch',text)\n",
    "    text = re.sub(r'[\\w]*s[\\w]*x[\\w]*','sex',text)\n",
    "    text = re.sub(r'[\\w]*s[\\w]*k[\\w]*','suck',text)\n",
    "    text = re.sub(r'[\\w]*nigg[\\w]*','suck',text)\n",
    "    text = re.sub(r'[\\w]*cock[\\w]*','dick',text)\n",
    "    text = re.sub(r'[\\w]*cunt[\\w]*','cunt',text)\n",
    "    text = re.sub(r'[\\w]*anal[\\w]*','anal',text)\n",
    "    text = re.sub(r'[\\w]*ha{2,}[\\w]*','haha',text)\n",
    "    text = re.sub(r'[\\w]*haha[\\w]*','haha',text)\n",
    "    text = re.sub(r'[\\w]*wiki[\\w]*','wikipedia',text)\n",
    "    text = re.sub(r'[\\w]*ency[\\w]ia[\\w]*','encyclopedia',text)   \n",
    "           \n",
    "    # Remove unwanted space\n",
    "    text = \" \".join(text.split())\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KJ8iXQUG-D3e"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    \n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "sent = decontracted(train['comment_text'].values[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tQERWCjoT4VV",
    "outputId": "f660f260-70e7-4fa4-a96e-f705a7f040ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However, the Moonlite edit noted by golden daph was me (on optus ...)  Wake up wikkis.  So funny\n"
     ]
    }
   ],
   "source": [
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZ1DrhgeUEAw"
   },
   "outputs": [],
   "source": [
    "sent = re.sub('[^A-Za-z0-9]+', ' ', sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LnLSizsuUP8j",
    "outputId": "806f3432-789a-40d6-99fc-edb931c85044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However the Moonlite edit noted by golden daph was me on optus Wake up wikkis So funny\n"
     ]
    }
   ],
   "source": [
    "print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WoY-YzRkURrh"
   },
   "outputs": [],
   "source": [
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KY-KQIPZkP1i"
   },
   "source": [
    "### cleaning train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ooK74rDEUXzl"
   },
   "outputs": [],
   "source": [
    "\n",
    "clean_text_train = []\n",
    "#s = re.compile(r'[^A-Za-z\\.\\-\\?\\!\\,\\#\\@\\% ]',re.IGNORECASE)\n",
    "  \n",
    "for i in train['comment_text'].values:\n",
    "  sent = text_preprocess(i)\n",
    "  sent = re.sub('[^A-Za-z0-9]+',' ', sent)\n",
    "  \n",
    "  sent = ' '.join(e for e in sent.split() if e not in stopwords and len(e)>1)\n",
    "  clean_text_train.append(sent.lower().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGmK42e-kSLI"
   },
   "source": [
    "### Cleaning test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRS3S3LYlE7W"
   },
   "outputs": [],
   "source": [
    "clean_text_test = []\n",
    "for i in test['comment_text'].values:\n",
    "  sent = text_preprocess(i)\n",
    "  sent = re.sub('[^A-Za-z0-9]+',' ', sent)\n",
    "  \n",
    " \n",
    "  \n",
    "  sent = ' '.join(e for e in sent.split() if e not in stopwords and len(e)>1)\n",
    "  clean_text_test.append(sent.lower().strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uk05VVQ6Xdzj"
   },
   "outputs": [],
   "source": [
    "train['comment_text'] = clean_text_train\n",
    "test['comment_text'] = clean_text_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the vocabulary for the model to learn from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rFadhNrZLDuD"
   },
   "outputs": [],
   "source": [
    "def build_vocab(sentences,verbose = True):\n",
    "  vocab = {}\n",
    "  for sentance in tqdm(sentences, disable = (not verbose)):\n",
    "    for word in sentance:\n",
    "      try :\n",
    "        vocab[word]+=1\n",
    "      except KeyError:\n",
    "        vocab[word] =1\n",
    "  return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "z4sSq_zMLD5_",
    "outputId": "e670d8fb-570b-47e1-dd77-f179b7426102"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [00:01<00:00, 104572.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'explanation': 1771, 'edits': 9995, 'made': 9685, 'username': 1826, 'hardcore': 167}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "sentences = train['comment_text'].apply(lambda x:x.split()).values\n",
    "vocab = build_vocab(sentences)\n",
    "print({k: vocab[k] for k in list(vocab)[:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "_ZVoP8IjLD27",
    "outputId": "1b6a4772-b701-4443-936d-b3d421b638af"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "news_path = '/content/crawl-300d-2M.vec'\n",
    "embeddings_index = KeyedVectors.load_word2vec_format(news_path, binary=True,unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HZ4RlreoYACi"
   },
   "outputs": [],
   "source": [
    "import operator \n",
    "def check_coverage(vocab,embeddings_index):\n",
    "  a = {}\n",
    "  oov = {}\n",
    "  k = 0\n",
    "  i = 0\n",
    "  for word in tqdm(vocab):\n",
    "    try:\n",
    "      a[word] = embeddings_index[word]\n",
    "      k+=vocab[word]\n",
    "    except:\n",
    "      oov[word] = vocab[word]\n",
    "      i+=vocab[word]\n",
    "      pass\n",
    "  print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
    "  print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
    "  sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "  return sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "txTyCL4yYDxc",
    "outputId": "df234619-519d-4451-c66a-f6bc79bf4d06"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161625/161625 [00:00<00:00, 489674.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 0.64% of vocab\n",
      "Found embeddings for  6.85% of all text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "ReD_TR32Tf7a",
    "outputId": "18bfad5d-6169-4c2b-d861-2902250eb753"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec \n",
    "glove_file = datapath('/content/glove.twitter.27B.200d.txt')\n",
    "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "embeddings_index = KeyedVectors.load_word2vec_format(tmp_file)\n",
    "\n",
    " #= KeyedVectors.load_word2vec_format(news_path, binary=True,unicode_errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z6hapUI9MZh-"
   },
   "outputs": [],
   "source": [
    "import operator \n",
    "def check_coverage(vocab,embeddings_index):\n",
    "  a = {}\n",
    "  oov = {}\n",
    "  k = 0\n",
    "  i = 0\n",
    "  for word in tqdm(vocab):\n",
    "    try:\n",
    "      a[word] = embeddings_index[word]\n",
    "      k+=vocab[word]\n",
    "    except:\n",
    "      oov[word] = vocab[word]\n",
    "      i+=vocab[word]\n",
    "      pass\n",
    "  print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
    "  print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
    "  sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "  return sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "kaEzhA1LMZql",
    "outputId": "19830085-e5e5-4b2a-9281-cc4df7cd264b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161625/161625 [00:00<00:00, 349651.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 48.68% of vocab\n",
      "Found embeddings for  96.66% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Ptl2_a6ehaN"
   },
   "outputs": [],
   "source": [
    "lll = np.where(train['comment_text'].str.contains('oldid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "OiUW1UfIgltx",
    "outputId": "4bd3eaa5-2b45-47b1-e39a-ab6d6c6deeee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   868,   1175,   2336,   3304,   3996,   4440,   5122,   5720,\n",
       "          5969,   6622,   7970,  10847,  11185,  11430,  11591,  12416,\n",
       "         13326,  13849,  14407,  14498,  14630,  15288,  15301,  15457,\n",
       "         15508,  15908,  16075,  16806,  18046,  18717,  19190,  20017,\n",
       "         21140,  21352,  22736,  23361,  24869,  25539,  25585,  25814,\n",
       "         25885,  26373,  26651,  26892,  27500,  28136,  28377,  28461,\n",
       "         29515,  29524,  29972,  30681,  30943,  31431,  32015,  32154,\n",
       "         34083,  34201,  34299,  34445,  35306,  38032,  38583,  39126,\n",
       "         40033,  40171,  40388,  41383,  41609,  41762,  41869,  42131,\n",
       "         42245,  42262,  45164,  46021,  46249,  47252,  48228,  48357,\n",
       "         48445,  48559,  49232,  49366,  49447,  49793,  50002,  50198,\n",
       "         50371,  50833,  51375,  52297,  52329,  53628,  54331,  55570,\n",
       "         55609,  55624,  55891,  56815,  57326,  57983,  58452,  59555,\n",
       "         60032,  61167,  61503,  61904,  61991,  62209,  62730,  62903,\n",
       "         63498,  63596,  64207,  64750,  64753,  65065,  65128,  65370,\n",
       "         66013,  66654,  66804,  66990,  67350,  68637,  69566,  70126,\n",
       "         70172,  70308,  70508,  70786,  71852,  72303,  72352,  72416,\n",
       "         72446,  72749,  72777,  73724,  73929,  74337,  74480,  74589,\n",
       "         75154,  75639,  76120,  76377,  76587,  77136,  79524,  81037,\n",
       "         82787,  83263,  83343,  85115,  85586,  85900,  86354,  87494,\n",
       "         88416,  88848,  89122,  89526,  89877,  90100,  90188,  90564,\n",
       "         90758,  91965,  92369,  92443,  92973,  92997,  93547,  94194,\n",
       "         94445,  95034,  95992,  96014,  96502,  97138,  97228,  97520,\n",
       "         97792,  97999,  98366,  99131,  99214,  99256,  99336,  99831,\n",
       "        100273, 100698, 100913, 101489, 102005, 102603, 105089, 105701,\n",
       "        105772, 106440, 106668, 107259, 107328, 107515, 108204, 108558,\n",
       "        109656, 109827, 110042, 110378, 111312, 112051, 112267, 112459,\n",
       "        112507, 113235, 113308, 113536, 114195, 114982, 115527, 116876,\n",
       "        116878, 116984, 117264, 117502, 118604, 118691, 119617, 119718,\n",
       "        119783, 120351, 120751, 120888, 121489, 121535, 121628, 122272,\n",
       "        122901, 123230, 123396, 123443, 123785, 124809, 125530, 126203,\n",
       "        126237, 126247, 127063, 127286, 127446, 127493, 128043, 128459,\n",
       "        128917, 129296, 129337, 129515, 129860, 131025, 131423, 133607,\n",
       "        133851, 133977, 134191, 134248, 134405, 134521, 134622, 135078,\n",
       "        135405, 135949, 136857, 137061, 137085, 137377, 137590, 137637,\n",
       "        138792, 138848, 139166, 139446, 140050, 140396, 140523, 141761,\n",
       "        142065, 142428, 142456, 142575, 142878, 143017, 143038, 143082,\n",
       "        144337, 144359, 145023, 145399, 145432, 145975, 145981, 146252,\n",
       "        146476, 146699, 148004, 148313, 148739, 148879, 148888, 149468,\n",
       "        149700, 150589, 151841, 152332, 152421, 152789, 152907, 153227,\n",
       "        153429, 153616, 153644, 154290, 154324, 154390, 154480, 154948,\n",
       "        155597, 155618, 155972, 156470, 156776, 157155, 157265, 158185,\n",
       "        158424, 159105]),)"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "0ubo1B_me_BG",
    "outputId": "baf63043-a9c7-4f1b-8d36-12ccf75aa7c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seems insistent adding pointless rambling talk page forum make cut http bad en wikipedia org index php title talk axm rifle diff oldid keeps reverting removal'"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[868,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "EljSZUv5fwqv",
    "outputId": "3887a3b6-fdc6-444a-89ae-ccadadd2df25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"He's at it again. He seems insistent on adding pointless rambling on how the talk page isn't a forum just so he can make a cut at me.\\n\\nhttp://en.wikipedia.org/w/index.php?title=Talk%3AXM8_rifle&diff;=193022803&oldid;=192967373\\n\\nHe keeps reverting my removal of it.\""
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_a.iloc[868,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "id": "JFYx5rP3evPq",
    "outputId": "58bf7a35-38e8-4ae3-8af8-449c96a2213d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    10,    460,    484,    854,   1820,   4490,   4759,   6393,\n",
       "          7146,   7239,   7269,   7671,   8197,   8278,   8539,   8832,\n",
       "          9268,   9669,  10143,  10677,  10880,  11099,  11524,  12435,\n",
       "         13520,  13806,  15122,  15249,  15276,  15565,  17096,  17255,\n",
       "         18056,  18254,  20136,  20612,  21166,  22037,  22183,  22311,\n",
       "         23288,  23689,  23889,  24721,  24984,  26356,  26384,  27259,\n",
       "         27787,  27821,  27924,  28284,  28288,  28289,  28336,  28410,\n",
       "         28479,  28967,  29274,  29797,  29882,  30035,  31148,  31866,\n",
       "         32471,  32590,  32649,  33103,  34536,  34591,  34744,  35256,\n",
       "         35965,  36225,  36248,  36487,  36569,  38210,  38667,  38698,\n",
       "         39388,  39916,  40418,  40574,  40994,  41123,  41433,  41530,\n",
       "         41595,  41622,  41816,  42554,  42978,  43107,  43439,  43553,\n",
       "         44051,  44320,  44542,  45424,  45724,  46390,  46502,  46530,\n",
       "         46761,  46812,  47524,  47550,  48122,  48534,  49825,  50147,\n",
       "         50967,  51725,  51743,  52007,  52238,  52422,  52486,  52654,\n",
       "         52772,  53119,  54236,  54257,  54801,  54886,  55422,  55737,\n",
       "         56043,  56369,  56405,  56722,  56786,  56893,  57246,  57704,\n",
       "         57830,  57856,  58338,  58438,  58611,  58669,  59253,  59806,\n",
       "         60139,  60218,  60303,  60808,  61299,  61621,  61715,  62246,\n",
       "         62781,  63677,  64013,  64103,  65927,  66498,  68040,  68367,\n",
       "         68420,  68655,  68873,  69580,  71331,  71471,  71760,  71818,\n",
       "         71913,  72408,  73235,  73563,  73671,  73791,  74670,  74708,\n",
       "         77181,  77420,  77664,  77821,  77987,  78055,  79051,  79100,\n",
       "         79442,  80656,  81174,  81456,  81621,  82534,  82555,  82997,\n",
       "         83248,  84243,  84551,  84726,  85307,  85426,  85544,  86773,\n",
       "         87131,  88364,  90246,  90266,  90396,  90436,  90437,  90483,\n",
       "         90648,  91307,  92453,  93294,  93833,  93905,  94148,  94657,\n",
       "         95012,  95248,  97591,  98074,  98395, 101861, 102264, 102659,\n",
       "        103675, 103716, 103740, 104005, 104176, 104357, 105621, 105885,\n",
       "        106063, 106097, 106187, 106274, 107840, 108211, 108986, 109436,\n",
       "        109481, 109630, 109638, 110724, 110830, 111433, 111724, 112144,\n",
       "        112555, 112912, 114056, 114152, 114428, 114470, 114772, 115589,\n",
       "        115690, 115977, 117272, 117376, 117564, 118077, 118304, 118638,\n",
       "        119482, 119945, 120223, 120227, 120423, 120724, 120863, 121688,\n",
       "        122574, 122595, 124933, 125283, 125284, 125287, 126173, 126491,\n",
       "        128974, 129049, 129413, 129614, 129753, 129960, 129981, 130078,\n",
       "        130484, 131092, 131173, 131379, 132201, 132209, 133209, 134238,\n",
       "        134504, 134635, 135265, 135901, 136914, 137486, 138366, 140113,\n",
       "        140173, 140377, 140409, 141309, 141594, 141940, 142467, 142739,\n",
       "        143772, 143855, 144095, 144392, 145533, 146004, 146072, 146233,\n",
       "        147656, 148182, 148197, 148300, 148448, 149371, 149801, 149988,\n",
       "        150436, 150607, 150679, 150902, 152396, 158299, 158622, 158916,\n",
       "        159240, 159295]),)"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "cnDsjGKbMZ1U",
    "outputId": "9f53e7e5-6eeb-4813-da77-177c820594a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('contribs', 2706),\n",
       " ('npov', 1872),\n",
       " ('infobox', 1075),\n",
       " ('barnstar', 1034),\n",
       " ('unsourced', 916),\n",
       " ('disambiguation', 774),\n",
       " ('fffa', 713),\n",
       " ('arbcom', 650),\n",
       " ('verifiability', 633),\n",
       " ('yourselfgo', 621),\n",
       " ('userpage', 597),\n",
       " ('talkpage', 534),\n",
       " ('mothjer', 489),\n",
       " ('gfdl', 457),\n",
       " ('oldid', 433),\n",
       " ('philippineslong', 420),\n",
       " ('cellpadding', 373),\n",
       " ('unconstructive', 353),\n",
       " ('deneid', 331),\n",
       " ('deletions', 320),\n",
       " ('pagedelete', 312),\n",
       " ('notrhbysouthbanof', 308),\n",
       " ('mainpagebg', 304),\n",
       " ('adminship', 299),\n",
       " ('criminalwar', 279),\n",
       " ('bunksteve', 278),\n",
       " ('checkuser', 274),\n",
       " ('conformance', 274),\n",
       " ('copyvio', 261),\n",
       " ('boymamas', 258),\n",
       " ('ytmnd', 250),\n",
       " ('ffffff', 246),\n",
       " ('reversions', 242),\n",
       " ('unreferenced', 218),\n",
       " ('youbollocks', 217),\n",
       " ('incivility', 215),\n",
       " ('concernthanks', 212),\n",
       " ('turkic', 210),\n",
       " ('delanoy', 205),\n",
       " ('nhrhs', 195),\n",
       " ('sitush', 193),\n",
       " ('cellspacing', 190),\n",
       " ('ullmann', 186),\n",
       " ('userspace', 181),\n",
       " ('subsection', 181),\n",
       " ('centraliststupid', 179),\n",
       " ('macedonians', 178),\n",
       " ('infoboxes', 177),\n",
       " ('subpage', 165),\n",
       " ('sysop', 155)]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c26z3k7hMZzk"
   },
   "outputs": [],
   "source": [
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Et3B2SqMMZx4"
   },
   "outputs": [],
   "source": [
    "mispell_dict = {'contribs':'contributions',\n",
    "                'npov':'point of view',\n",
    "                'infobox':'information box',\n",
    "                'barnstar':'barn star',\n",
    "                'unsourced':'not source',\n",
    "                'disambiguation':'not ambiguous',\n",
    "                'fffa':'fuck',\n",
    "                'arbcom':'arbitration committee',\n",
    "                'verifiability':'verify',\n",
    "                'yourselfgo':'yourself go',\n",
    "                'userpage':'user page',\n",
    "                'talkpage':'talk page',\n",
    "                'mothjer':'mother',\n",
    "                'gfdl':'free',\n",
    "                'oldid':'link',\n",
    "                'philippineslong': 'philippine king',\n",
    "                'cellpadding': 'cell padding',\n",
    "                'unconstructive': 'not constructive',\n",
    "                'deneid':'deny',\n",
    "                'deletions': 'delete',\n",
    "                'pagedelete':'page delete',\n",
    "                'notrhbysouthbanof':'not by south',\n",
    "                'mainpagebg': 'main page',\n",
    "                'adminship':'admin',\n",
    "                'criminalwar':'criminal war',\n",
    "                'ffffff':'fuck'\n",
    "\n",
    "                }\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JzC2vvHxMZvr"
   },
   "outputs": [],
   "source": [
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "e8juaVMBa2RL",
    "outputId": "0f5222a3-daac-49b3-abd3-b411dc2af4ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [00:00<00:00, 209179.31it/s]\n",
      "100%|██████████| 159571/159571 [00:01<00:00, 108226.51it/s]\n"
     ]
    }
   ],
   "source": [
    "train[\"comment_text\"] = train[\"comment_text\"].apply(lambda x: replace_typical_misspell(x))\n",
    "sentences = train[\"comment_text\"].apply(lambda x: x.split())\n",
    "to_remove = ['a','to','of','and']\n",
    "sentences = [[word for word in sentence if not word in to_remove] for sentence in tqdm(sentences)]\n",
    "vocab = build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Zc5Tupaza2if",
    "outputId": "00f77fb0-ae90-47e9-d01b-1240e9e3c0d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 161579/161579 [00:00<00:00, 356188.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 48.70% of vocab\n",
      "Found embeddings for  96.96% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embeddings_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lMCFa4wz5Bx1"
   },
   "source": [
    "### Increase vocabulary fed to a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsaJoMgAnBDz"
   },
   "outputs": [],
   "source": [
    "#Tried to increase vocabulary of the model. Didn't work\n",
    "'''def translate(comment, language):\n",
    "    if hasattr(comment, \"decode\"):\n",
    "        comment = comment.decode(\"utf-8\")\n",
    "\n",
    "    text = TextBlob(comment)\n",
    "    try:\n",
    "        text = text.translate(to=language)\n",
    "        text = text.translate(to=\"en\")\n",
    "    except NotTranslated:\n",
    "        pass\n",
    "\n",
    "    return str(text)\n",
    "\n",
    "def main():\n",
    "    \n",
    "\n",
    "    \n",
    "    languages = [\"es\", \"de\", \"fr\"]\n",
    "    \n",
    "    comments_list = train[\"comment_text\"].str.lower().fillna('something').values\n",
    "\n",
    "    if not os.path.exists(\"/content/drive/My Drive/\"):\n",
    "        os.mkdir(\"/content/drive/My Drive/\")\n",
    "\n",
    "    parallel = Parallel(n_jobs = -1,backend=\"threading\", verbose=5)\n",
    "    for language in languages:\n",
    "        print('Translate comments using \"{0}\" language'.format(language))\n",
    "        translated_data = parallel(delayed(translate)(comment, language) for comment in comments_list)\n",
    "        train[\"comment_text\"] = translated_data\n",
    "\n",
    "        result_path = os.path.join(args.result_path, \"train_\" + language + \".csv\")\n",
    "        train.to_csv(result_path, index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDtG2tNDWHtw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "POjfvSd5oTeH"
   },
   "source": [
    "### Modeling on Twitter embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eXCag3pD9BS4"
   },
   "outputs": [],
   "source": [
    "max_features = 100000\n",
    "maxlen = 150\n",
    "embed_size = 200\n",
    "batch_size = 128\n",
    "n_splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJsHZtgS9BPE"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "np.random.seed(32)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras.models import Model, load_model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras import backend as K\n",
    "from keras.engine import InputSpec, Layer\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "\n",
    "max_features = 272330\n",
    "maxlen = 150\n",
    "embed_size = 200\n",
    "batch_size = 2048\n",
    "n_splits = 4\n",
    "\n",
    "\n",
    "# Classs for evaluating the metric\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch, score))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the vocabulary and form word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mWMY0B4HkqDo"
   },
   "outputs": [],
   "source": [
    "#Load embedding file, seperate train and test classes\n",
    "EMBEDDING_FILE='/content/glove.twitter.27B.200d.txt'\n",
    "train = pd.read_csv('/content/drive/My Drive/self2/train.csv')\n",
    "test = pd.read_csv('/content/drive/My Drive/self2/test.csv')\n",
    "\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# load Clean text\n",
    "train['comment_text'] = clean_text_train\n",
    "test['comment_text'] = clean_text_test\n",
    "\n",
    "\n",
    "# Vectorize comments\n",
    "list_sentences_train = train[\"comment_text\"].str.lower().fillna(\"_na_\").values\n",
    "list_sentences_test = test[\"comment_text\"].str.lower().fillna(\"_na_\").values\n",
    "    \n",
    "tokenizer = Tokenizer(num_words = max_features, lower = True,filters='\"#$%&()*+,-./:;=@[\\\\]^_`“<>{|}~\\t\\n') # not filtering out ! and ?, < >\n",
    "# Fit on both train and test to take all the vocabulary\n",
    "# People will question why take test. it is exposing to a wider vocabulary                      \n",
    "tokenizer.fit_on_texts(list(list_sentences_train)+list(list_sentences_test))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "#padding the sequences to a maxlen of 150 per comment\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
    "#Load word vector\n",
    "def get_coefs(word,*arr): \n",
    "  return word, np.asarray(arr, dtype='float32')    \n",
    "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(EMBEDDING_FILE, encoding='utf-8'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "La826WhnlHfP",
    "outputId": "893f6e4b-9410-47f0-b877-df644fd9a983"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272337"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Oe_0dpHlIzo"
   },
   "outputs": [],
   "source": [
    "# creare embedding matrix\n",
    "nb_words = min(max_features, len(word_index)) \n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "    # we need to create a matrix for each word in the dataset - embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbuNKHH6mpvV"
   },
   "outputs": [],
   "source": [
    "# use stratified k folds to split data into train and test\n",
    "# we are using stratified k folds in htis case because train_test_split won't work\n",
    "folds = StratifiedKFold(n_splits = n_splits, shuffle = True, random_state=25)\n",
    "oof = np.empty([len(X_t),len(list_classes)])\n",
    "sub_preds = np.zeros([len(X_te),len(list_classes)])\n",
    "foldwise_auc = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qZ8rn44oyW8"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, MaxPool1D, BatchNormalization, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "LgvCf5k6oJjm",
    "outputId": "3afc152f-b259-44f4-abfc-b828cd39f777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running fold 0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:200: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 119678 samples, validate on 39893 samples\n",
      "Epoch 1/4\n",
      "119678/119678 [==============================] - 13s 109us/step - loss: 0.3112 - acc: 0.8706 - val_loss: 0.0642 - val_acc: 0.9799\n",
      "\n",
      " ROC-AUC - epoch: 0 - score: 0.953532\n",
      "Epoch 2/4\n",
      "119678/119678 [==============================] - 6s 49us/step - loss: 0.0609 - acc: 0.9801 - val_loss: 0.0533 - val_acc: 0.9811\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.971827\n",
      "Epoch 3/4\n",
      "119678/119678 [==============================] - 6s 49us/step - loss: 0.0514 - acc: 0.9816 - val_loss: 0.0512 - val_acc: 0.9816\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.975613\n",
      "Epoch 4/4\n",
      "119678/119678 [==============================] - 6s 49us/step - loss: 0.0474 - acc: 0.9825 - val_loss: 0.0506 - val_acc: 0.9815\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.976782\n",
      "39893/39893 [==============================] - 1s 15us/step\n",
      "153164/153164 [==============================] - 2s 13us/step\n",
      "Running fold 1\n",
      "Train on 119678 samples, validate on 39893 samples\n",
      "Epoch 1/4\n",
      "119678/119678 [==============================] - 7s 55us/step - loss: 0.3186 - acc: 0.8680 - val_loss: 0.0647 - val_acc: 0.9793\n",
      "\n",
      " ROC-AUC - epoch: 0 - score: 0.945583\n",
      "Epoch 2/4\n",
      "119678/119678 [==============================] - 6s 50us/step - loss: 0.0613 - acc: 0.9800 - val_loss: 0.0545 - val_acc: 0.9805\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.968221\n",
      "Epoch 3/4\n",
      "119678/119678 [==============================] - 6s 50us/step - loss: 0.0514 - acc: 0.9815 - val_loss: 0.0525 - val_acc: 0.9807\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.975456\n",
      "Epoch 4/4\n",
      "119678/119678 [==============================] - 6s 49us/step - loss: 0.0473 - acc: 0.9825 - val_loss: 0.0517 - val_acc: 0.9806\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.978288\n",
      "39893/39893 [==============================] - 0s 12us/step\n",
      "153164/153164 [==============================] - 2s 12us/step\n",
      "Running fold 2\n",
      "Train on 119678 samples, validate on 39893 samples\n",
      "Epoch 1/4\n",
      "119678/119678 [==============================] - 7s 60us/step - loss: 0.3220 - acc: 0.8666 - val_loss: 0.0680 - val_acc: 0.9797\n",
      "\n",
      " ROC-AUC - epoch: 0 - score: 0.941202\n",
      "Epoch 2/4\n",
      "119678/119678 [==============================] - 6s 50us/step - loss: 0.0614 - acc: 0.9804 - val_loss: 0.0552 - val_acc: 0.9807\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.970431\n",
      "Epoch 3/4\n",
      "119678/119678 [==============================] - 6s 49us/step - loss: 0.0513 - acc: 0.9816 - val_loss: 0.0521 - val_acc: 0.9811\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.974577\n",
      "Epoch 4/4\n",
      "119678/119678 [==============================] - 6s 49us/step - loss: 0.0470 - acc: 0.9827 - val_loss: 0.0516 - val_acc: 0.9812\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.975824\n",
      "39893/39893 [==============================] - 0s 12us/step\n",
      "153164/153164 [==============================] - 2s 13us/step\n",
      "Running fold 3\n",
      "Train on 119679 samples, validate on 39892 samples\n",
      "Epoch 1/4\n",
      "119679/119679 [==============================] - 7s 59us/step - loss: 0.3014 - acc: 0.8743 - val_loss: 0.0647 - val_acc: 0.9801\n",
      "\n",
      " ROC-AUC - epoch: 0 - score: 0.946424\n",
      "Epoch 2/4\n",
      "119679/119679 [==============================] - 6s 49us/step - loss: 0.0599 - acc: 0.9803 - val_loss: 0.0541 - val_acc: 0.9809\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.967975\n",
      "Epoch 3/4\n",
      "119679/119679 [==============================] - 6s 50us/step - loss: 0.0509 - acc: 0.9817 - val_loss: 0.0512 - val_acc: 0.9813\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.976223\n",
      "Epoch 4/4\n",
      "119679/119679 [==============================] - 6s 50us/step - loss: 0.0473 - acc: 0.9824 - val_loss: 0.0509 - val_acc: 0.9813\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.977174\n",
      "39892/39892 [==============================] - 1s 14us/step\n",
      "153164/153164 [==============================] - 2s 13us/step\n",
      "AUC for full run: 0.976755\n"
     ]
    }
   ],
   "source": [
    "#ttps://www.kaggle.com/ogrellier/kfold-or-stratifiedkfold\n",
    "#https://www.kaggle.com/christofhenkel/inceptioncnn-with-flip\n",
    "#https://www.kaggle.com/c/quora-insincere-questions-classification/discussion/79911\n",
    "# triain the model\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(y[:,0], y[:,0])): #StratifiedKFold expects array of shape (n,)\n",
    "    filter_sizes = [1,2,3,5]\n",
    "  \n",
    "    X_train, y_train = X_t[trn_idx], y[trn_idx]\n",
    "    X_val, y_val = X_t[val_idx], y[val_idx]\n",
    "    num_filters = 36    \n",
    "    print(\"Running fold %d\" % fold_)     \n",
    "        \n",
    "    ra_val = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
    "    earlystop = EarlyStopping(monitor='val_loss', mode=\"min\", patience=5, verbose=1) \n",
    "        \n",
    "    def build_model(lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0):\n",
    "        inp = Input(shape = (maxlen,))\n",
    "        x = Embedding(max_features, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
    "        \n",
    "        x = SpatialDropout1D(dr)(x)\n",
    "        conv_0 = Conv1D(num_filters, kernel_size=(filter_sizes[0]),\n",
    "                                 kernel_initializer='he_normal', activation='elu')(x)\n",
    "        conv_1 = Conv1D(num_filters, kernel_size=(filter_sizes[1]),\n",
    "                                 kernel_initializer='he_normal', activation='elu')(x)\n",
    "        conv_2 = Conv1D(num_filters, kernel_size=(filter_sizes[2]), \n",
    "                                 kernel_initializer='he_normal', activation='elu')(x)\n",
    "        conv_3 = Conv1D(num_filters, kernel_size=(filter_sizes[3]),\n",
    "                                 kernel_initializer='he_normal', activation='elu')(x)\n",
    "\n",
    "        maxpool_0 = MaxPool1D(pool_size=(maxlen - filter_sizes[0] + 1))(conv_0)\n",
    "        maxpool_1 = MaxPool1D(pool_size=(maxlen - filter_sizes[1] + 1))(conv_1)\n",
    "        maxpool_2 = MaxPool1D(pool_size=(maxlen - filter_sizes[2] + 1))(conv_2)\n",
    "        maxpool_3 = MaxPool1D(pool_size=(maxlen - filter_sizes[3] + 1))(conv_3)\n",
    "\n",
    "        z = Concatenate(axis=1)([maxpool_0, maxpool_1, maxpool_2, maxpool_3])   \n",
    "        z = Flatten()(z)\n",
    "        z = BatchNormalization()(z)\n",
    "        outp = Dense(6, activation=\"sigmoid\")(z)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "        model = Model(inputs = inp, outputs = outp)\n",
    "        model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
    "        model.fit(X_train, y_train, batch_size = 512, epochs = 4, validation_data = (X_val, y_val), \n",
    "                                verbose = 1, callbacks = [ra_val, earlystop])\n",
    "            \n",
    "        return model\n",
    "                                         \n",
    "    model = build_model(lr = 1e-3, lr_d = 0, units = 144, dr = 0.2)\n",
    "        \n",
    "    pred = model.predict(X_val, batch_size = 1024, verbose = 1)       \n",
    "    #Save model after every epoch   \n",
    "    filename = '/content/drive/My Drive/twitter_' + str(fold_) + '.h5'   \n",
    "    model.save(filename)\n",
    "    oof[val_idx] = pred\n",
    "        \n",
    "    sub_preds += model.predict([X_te], batch_size=1024, verbose=1) / n_splits\n",
    "            \n",
    "auc=0\n",
    "for i in range(len(list_classes)):\n",
    "    auc += roc_auc_score(y[:,i], oof[:,i]) / len(list_classes)\n",
    "    \n",
    "print(\"AUC for full run: %.6f\" % auc)\n",
    "    \n",
    "validation = pd.DataFrame(oof, columns = list_classes)\n",
    "validation.to_csv('validation_fasttext_bgrucnn.csv', index=False) \n",
    "    \n",
    "submission = pd.concat([test['id'], pd.DataFrame(sub_preds, columns = list_classes)], axis=1)\n",
    "submission.to_csv('submission_fasttext_bgrucnn.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This Case study involves classifying a text to one of the 6 classes :- Toxic, Severe_toxic, Obscene, Threat, Insult, Identity_hate.\n",
    "- I decided to use the Fasttext and twitter word vectors to try and model the vocabulary of the comment.\n",
    "- I imported the dataset to check for the number of comments under each class checked for any null values. The total number of clean comments are 89% approx.\n",
    "- I then used some simple regex to clean the train and text data to make the comments as simmilar as possible without changing the meaning of the sentence.\n",
    "- I also tried to extend the vocabulary by translating the sentences to a different language and translating them back to english. The idea is that this would expose the model to a larger vocabulary. This could not work as google translate api doesn't allow translating beyond a certain limit for free.\n",
    "- I also tried manual find and replace for words that had the same meaning but different spellings. This was all done in part to clean the test as much as posisible. Problems like these boil down to the quality of the dataset.\n",
    "- After this, I checked which word vectors account for the maximum amount of vocabulary in the dataset. Fast-text word vectors could only account for a measly 0.64% of the entire vocabulary, whereas twitter word vectors could account for around 48% of the vocabulary. Hence the embedding matrix was created using the twitter word vectors.\n",
    "- A deep learning model using Convolution layers was built and ROC-AUC score was used as a performance metric. The Kaggle dashboard gave the best value of ROC-AUC score as 98.12 which is a top 50% solution.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ToxicCommentClassification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
